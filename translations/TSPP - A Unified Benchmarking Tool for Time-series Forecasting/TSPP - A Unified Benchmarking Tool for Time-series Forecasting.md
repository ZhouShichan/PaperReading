# TSPP - A Unified Benchmarking Tool for Time-series Forecasting

> J. Bączek et al., “TSPP: A Unified Benchmarking Tool for Time-series Forecasting.” arXiv, Dec. 28, 2023. Accessed: Dec. 31, 2023. [Online]. Available: <http://arxiv.org/abs/2312.17100>

## 摘要

尽管机器学习取得了显著的进展，但重点主要集中在数据获取和模型创建上。然而，在实际环境中全面评估机器学习解决方案需要整个流程的标准化。这一需求在时间序列预测中尤为迫切，因为各种各样的设置妨碍了对不同方法进行有意义的比较。为了弥合这一差距，我们提出了一个统一的基准测试框架，揭示了在开发时间序列预测模型时涉及的关键建模和机器学习决策。该框架促进了模型和数据集的无缝集成，有助于从业者和研究人员在他们的开发工作中。我们在这一框架内对最近提出的模型进行了基准测试，展示了经过精心实施的深度学习模型只需付出最小的努力，就能与需要进行大量特征工程和专业知识的梯度提升决策树相匹敌。该框架可以在[这里](https://github.com/NVIDIA/DeepLearningExamples/tree/master/Tools/PyTorch/TimeSeriesPredictionPlatform)。

## 1. 介绍

时间序列预测在金融、天气预报、需求预测等领域发挥着至关重要的作用。准确的预测使企业能够优化决策、增强运营并提高整体效率。然而，时间序列数据固有的复杂性，包括趋势、噪声、缺失值和变量之间不断变化的关系，对实现准确预测提出了重大挑战。
为了应对时间序列预测的挑战，出现了多种方法。
梯度增强机(Gradient boosting machines, GBM)因其有效性而在 Kaggle 竞赛中变得流行，但需要大量的特征工程工作。虽然很有前途，但深度学习模型独立使用的频率较低，主要是由于数据限制。NN3 竞赛旨在展示神经网络(NNs)在时间序列预测方面的可行性，但 2011 年发表的初步结果令人失望，突出了统计方法的主导地位。2017 年的 Web 流量时间序列预测竞赛进一步证实了这一点，机器学习方法在丰富且同质的数据中表现更好。同样，著名的 M4 竞争证明了统计方法在异构数据上的优越性。
尽管有这种趋势，RNN 和统计模型相结合的集成赢得了比赛，尽管尚不清楚这是否标志着向深度学习的转变。随后的 M5 竞赛，利用沃尔玛的真实销售数据，见证了梯度增强机的优势，第二名的解决方案利用了 GBM 和神经网络的集合。这表明向深度学习架构的潜在转变将成为时间序列预测管道中不可或缺的一部分。
各种时间序列预测方法的快速发展使得很难对高性能深度学习模型的构成进行比较和建立共识。虽然存在标准化数据集以对这些模型进行基准测试的努力，但比较往往忽略了整个机器学习生命周期中的关键方面，导致结果模糊，对模型改进提供的指导有限。例如，训练神经网络的既定技术，如课程学习、指数移动平均和漂移估计，很容易获得，但在目前的文献中很大程度上被忽视了。这些研究经常采用以模型为中心的视角，只关注预测算法本身。相反，我们的工作旨在通过全面考虑机器学习生命周期中的所有活动部分来解决这一差距。
为了实现这一目标，我们提出了一个统一的基准框架，使预测模型的评估标准化。这一框架有助于实施和比较最具影响力的时间序列预测模型，从而能够更全面和客观地评估其业绩。
我们的贡献如下:

1. 我们开发并开源了时间序列预测基准的标准化框架。该框架具有模块化组件，可以快速轻松地集成数据集、模型和训练技术。
2. 使用所提出的框架，重新实现和改进了最近流行的用于时间序列预测的深度学习模型，评估了它们在这些方法中常用数据集上的性能。
3. 从分配给这些模型调优和比较的大量计算资源中概述了各种观察结果。完整的代码和详细的实验报告在[这里](https://github.com/NVIDIA/DeepLearningExamples/tree/master/Tools/PyTorch/TimeSeriesPredictionPlatform)。

## 2. 相关工作

时间序列预测的大多数研究都是围绕竞争展开的，参与者使用不同的方法。这些方法主要分为三大类:

1. 统计方法，如 ARIMA;
1. 经典机器学习算法，包括支持向量机、梯度增强机;
1. 基于神经网络的方法，如 TFT23、NHITS 和 NBEATS 和 MTGNN。

然而，在发表的方法中使用具有不同设置的数据集阻碍了准确的性能评估，并且难以确定明确的领先者。
尽管标准化基准实践的努力，跨方法的数据集的可变性阻碍了有意义的比较。在中，作者强调了数据集比较的局限性，因为不同的特征，如大小、特征数量和噪声水平。类似的观察结果也得到了莫纳什时间序列预测基准等基准的响应，该基准专门为模型比较整理数据集。然而，像这样的倡议侧重于将模型运行模式(单变量/多变量，局部/全局)分类作为比较的基础。相比之下，采用以模型为中心的方法，探索神经网络的架构变化。他们的发现表明，==缺乏一个通用的最佳架构，突出了模型性能的数据依赖性==。虽然这些研究承认缺乏标准化，但它们的重点要么以模型为中心，要么以数据为中心，这阻碍了对两者之间相互作用的全面理解。建立一个同时考虑这两个方面的标准化框架对于促进有意义的比较和时间序列预测的进步至关重要。
虽然深度学习模型越来越受欢迎，但最近的研究挑战了它们在更简单、更可解释的方法上的有效性。然而，我们认为深度学习模型并没有得到应有的认可。通过对整个机器学习生命周期的仔细考虑和适当的优化技术，我们相信这些模型可以实现超出其最初声称的功能的进一步改进.

## 3. 时序预测架构

时间序列是按时间索引的一系列数据点，而预测则是从过去的历史数据中预测未来值的过程。尽管这个任务在言语中可以简单地描述，但对于这些模型来说，机器学习的生命周期却相当复杂，需要一个全面的机器学习流程，从数据的整理到模型的部署都得到覆盖。提出的框架概述如图 1 所示，包括以下组件：

- **数据**：对数据进行改进和整理，使其适用于模型训练的决策。这包括数据的选择、整理和清理。
- **训练**：关于输入数据和模型的决策，以提高下游性能。这包括根据输入数据定制的模型设计、优化和选择标准。
- **推断**：关于部署和对未知数据输入进行预测的决策。
- **调谐器**：一旦上述组件被定义，该组件选择顶级配置并将其用于部署后的模型监控、重新训练和不确定性量化.

### 3.1 任务描述

在时间序列预测中，我们有一个时间序列 $X=(x_{1},\ldots,x_{T}),x_{i}\in\mathbb{R}$，以预设的预测视界 $h\in\mathbb{N}$ 为目标。然后定义了质量指标 $\mathcal{L}:\mathbb{R}^h\times\mathbb{R}^h\to\mathbb{R}$ 来评价预测模型 $M:\mathbb{R}^T\to\mathbb{R}^h$ 的预测质量。目标是最小化这个度量$M:\mathbb{R}^T\to\mathbb{R}^h$的期望，其中 $X^{+}=(x_{T+1},\ldots,x_{T+h})$ 是一个表示真实未来值的序列。

### 3.2 数据方面

数据是机器学习应用程序的关键组成部分，并影响管道中做出的大多数决策。现实世界的时间序列数据集通常包含缺失值、噪声，并且不遵循许多基准数据集中看到的规律。大多数先前的工作认为数据是静态的，并且仅在模型/算法级别寻求改进。相反，在进行比较时，我们将数据修改视为整体建模工作的一部分。
扩展时间序列的定义。数据集 $\mathcal{D}=(X,C)$ 包含了一组序列 $X= \{X^1,\ldots,X^n\}$，其中 $X^i=(x_1^i,x_2^i,\ldots,x_T^i)$，$T$是时间序列的长度。与此同时，伴随 $X$ 的是一组协变量 $C = {C^1, \ldots , C^n}$，$C^i = (c^i_1, c^i_2, \ldots , c^i_T)$，其中时间序列和协变量都可以是任意维度的向量，即 $x_t^i\in \mathbb{R} ^d$ 和 $c_t^i\in \mathbb{R} ^k$，$d$ 和 $k$ 分别是时间序列和协变量的维度。当 $d = 1$ 时，时间序列是单变量的；当 $d > 1$ 时，被视为多变量。
在这种数据集定义方式下，可能违反以下假设：

1. **$X$ 中的序列相互独立** - 这种情况下，数据集 $\mathcal{D}=(X,C,S)$ 中可能包含静态数据 $S$，其中可能包含序列之间的相关信息（比如用于数据收集的传感器的空间位置）；
2. **$X$ 中的序列具有相同的长度** - 这种情况下，长度 $T$ 可以在不同序列之间变化；
3. **缺乏对未来的先验知识，实际上这可能包含在协变量或某个变量中** - 这种情况下，协变量 $C$ 被分为两个不相交的集合：$C_o$ 包含我们对未来没有知识的协变量，而 $C_k$ 包含我们具有这种知识的协变量。例如，我们可能预先知道未来会发生的事件，或者我们对某些变量有完全控制权。

利用数据集 $\mathcal{D}$，数据分割模块生成相应的训练集 $\mathcal{D}_{train}$、验证集 $\mathcal{D}_{val}$ 和测试集 $\mathcal{D}_{test}$，并在各种方法中保持不变。然后，数据的形状会显著影响下游模型的使用方式。例如，底层方法可能对动态范围敏感，可能需要进行归一化，或者不能接受协变量作为附加输入，因此必须将其排除。预处理函数 $p$ 实现多种功能，如过滤、异常值去除、插补、标签修正、特征选择等。在每个预处理步骤，可能有多个可行的替代方法可应用于数据，以提高其对特定模型的质量，并在评估整体性能时应向调谐器公开。总体来说，$p$ 被设计以满足特定的建模条件和下游假设。

### 3.3 训练方面

一旦数据集准备好了，我们必须确定模型训练需要多少探索以及如何确保可靠的训练。一般来说，预测模型 $M$ 是一个函数，它将一系列观测值和协变量作为输入，并预测一系列预测输出：$$M(S,X,C)\mapsto\hat{X}^+\in\mathbb{R}^{d\times h}$$
由于计算资源有限，限制用于训练的数据很常见。这可以通过回溯窗口来实现，不同的模型有不同的回溯窗口。一个标准假设是，序列的最新值包含了与未来预测最相关的先验值。使用一个固定长度的回视窗口 $l$，从需要进行未来预测的索引开始。更具体地说，让 $X^{\prime}$ 成为从 $X$ 中截取最后 $l$ 个观测值的序列集合，即 $X^{\prime}:=\{(x_{T-l+1}^i,\ldots,x_T^i)|(x_1^i,\ldots x_T^i)\in X\}$，并类似地定义 $C_k^{\prime}$ 和 $C_o^{\prime}$ 。遵循该假设，使用回溯窗口对历史数据进行近似处理：$$M(S,X,C_k,C_o)\approx M(S,X',C'_k,C'_o)$$ 其中，模型 $M$ 既可以在全局水平上运行，即使用数据集中所有可用的时间序列来估计模型参数；也可以在局部水平上运行，即使用数据集中的单个时间序列来估计模型参数。$M$ 的选择还可能导致不同的训练参数，其中包括优化参数、初始化、目标、是否应用课程学习、指数移动平均（EMA）等。这些参数集还必须与模型探索一起考虑，这将在第 3.5 节中讨论。因此，考虑控制模型复杂度和训练复杂度的参数范围非常重要。

### 3.4 推理方面

成功的模型通常依赖于对其旨在预测的序列的某些假设，如数据的静止性或无间隙。一般来说，模型预测的预测窗口由下游任务设定，结果是预测结果 $X^i_{+} = (x^i_{T+1}, \ldots , x^i_{T+h})$。与 3.2 节中定义的转换原始序列的预处理函数 $p$ 相似，后处理函数 $p^{\prime}$ 对预测窗口进行操作，以逆转预处理步骤的某些方面（例如，归一化），并纳入有关如何解释预测窗口的领域专家知识（例如，产品销售额不能为负并设置下限）。

成功的模型通常依赖于对其旨在预测的数据的某些假设，如序列的静止性和无间隙。这些假设简化了建模过程，使预测更加准确。然而，现实世界的数据很少能完全符合这些假设。为了弥补这一点，通常会采用类似于预处理的技术，将原始数据转换成满足模型输出要求的格式。

模型预测的预测窗口通常由其服务的下游任务决定。例如，一个销售预测模型的设计目的可能是预测下个月的产品需求，预测窗口 $X^i_{+} = (x^i_{T+1}, \ldots , x^i_{T+h})$，其中 $T$ 是当前时间，$h$ 是预测范围。

在预处理为建模准备数据的同时，后处理步骤确保预测值可解释并与领域知识保持一致。后处理函数（用 $p^{\prime}$ 表示）在预测窗口上运行，并执行几项关键任务。它逆转预处理步骤的某些方面，如去归一化，将预测值返回到原始单位。此外，它还纳入了特定领域的知识，以确保预测符合现实世界的限制条件。例如，产品销售的后处理函数可能会强制执行非负约束，防止模型预测出负的销售数字。

通过结合预处理和后处理步骤，我们可以充分利用机器学习模型的优势，同时确保预测结果可解释并适用于特定领域。

### 3.5 调谐器超参数选择

在前面的部分，我们考虑了一系列的超参数配置空间，这些空间必须被探索，以确保可靠的模型训练和比较。对于作者来说，复现其他论文中的训练设定结果的动机很小，这反过来可能会让参考模型处于不利地位。为了确保公平的比较，模型应该在同一框架内实现，并且可以访问流水线中的所有同样的修改以及超参数优化（HPO）算法。我们让 $\Lambda=\Lambda_{1}\times\Lambda_{2}\times\cdots\Lambda_{n}$ 来定义所有超参数的空间，并且让 $\lambda \in \Lambda$ 来代表这个超参数空间中的一个向量。在超参数集合中，每个超参数都有一系列考虑过的范围，这个范围被记作 $\mathcal{A}$。超参数由特定于模型的 $\lambda_{M}$ 和特定于数据集或训练的参数 $\lambda_{P}$ 组成，即 $\lambda=[\lambda_{M};\lambda_{P}]$。然后，调整器的目标是要找到

$$\lambda_{top}=\arg\min_{\lambda\in\mathcal{A}}\mathbb{E}_{(D_{train}\cup D_{val},D_{test})\sim\mathcal{D}}V(\mathcal{L},\lambda,D_{train}\cup D_{val},D_{test}),$$

其中，$V$ 测量的是超参数为 $\mathcal{A}_{\lambda}$ 的框架集的损失。在为每个模型运行这个调整器时，会使用固定的预算 $B$ 来寻找最佳的配置，这个预算是以运行相同系统和环境的流水线的计算小时数定义的。为了得到最终的模型 $M$，我们使用了一个两步优化过程：

1. 从 A 中对一个超参数 $\lambda$ 进行采样，
2. 使用 $D_{train}\cup D_{val}$ 对模型权重使用优化程序。

当在验证集上评估的停止条件满足时，模型优化程序就会终止。第二步会一直重复，直到 HPO 的预算 $B$ 用尽。在下一节中，我们将解释如何评估模型的便携性和泛化性。这个过程在图 2 和附录的第 B 节中有更详细的流程图表述。

<!-- TODO 之后补图 -->

### 3.6 模型选择和评估

为了比较模型，仅仅评估一个训练过的模型是不够的，因为这样的任务在性能上存在内在的差异。例如，仅仅更改随机种子就会导致精度的变化，这可能被视为在[29]中所做的具有统计显著性。相反，调整器找到的最佳配置被用来初始化参数模型家族 $q(\theta|\mathcal{D},\lambda_{top})$ ，从此家族中采样和训练模型。训练过的模型被记作 $p(y|\mathcal{D},\theta)$ 。我们从 $\theta_{m}\sim q(\theta|\mathcal{D},\lambda_{top})$ 中采样出 K 个这样的模型 θm，并使用损失函数进行评估：

$$\mathbb{E}[\mathcal{L}(p(y|\mathcal{D};\theta),y)]\approx\frac{1}{K}\sum_{m=1}^{K}\mathcal{L}(p(y|\mathcal{D},\theta_m),y)$$

同样，损失的方差被计算出来，表示为 $\sigma^2=\mathrm{Var}(\mathcal{L}(p(y|\mathcal{D};\theta),y))$ 。为了比较两个模型，我们构造了一个统计测试，以确定模型 $M_1$ 是否比另一个模型 $M_2$ 有更低的期望损失。设 $q_1$ 代表模型 $M_1$ 的参数模型家族，以及其期望损失 $E_1$ 和方差 $\sigma^2_1$。同样的，设 $q_2$ 代表 $M_2$ 的参数模型，$E_2$ 为期望损失，$\sigma^2_2$ 为其方差。零假设设立为 $h_0$：_模型的期望损失之间没有显著的差异_。然后，$t$ 值由下式给出:

$$t=\frac{E_1-E_2}{\frac{1}{K}\sqrt{\sigma_1^2+\sigma_2^2}}$$

通过指定一个期望的显著性水平 $\alpha$，如果 $t > t_{crit}$，那么就拒绝零假设 $h_0$，其中 $t_{crit}$ 是从 _t_ 分布表中取出的。在存在显著差异的情况下，可以简单地通过选择期望损失较低的那个模型来确定哪个模型更好。这种比较方法对随机初始化和训练设置具有鲁棒性，也更好地反映了模型在数据集间的可移植性。

## 4. 实验

### 4.1 数据集详情

由于数据特征的多样性，时间序列模型基准测试可能具有挑战性。 与自然语言处理（NLP）或计算机视觉（CV）中的数据往往具有更一致的特征不同，时间序列数据在结构和复杂性方面可能会有很大差异[14]。这使得很难准确比较不同模型和方法的性能，因为可能没有一种适用于所有数据集的通用方法。以数据为中心的方法将数据转换方式的变化视为额外的可调参数。
在我们的实验中，考虑了四个在时间序列预测基准测试中广泛使用的数据集（Electricity，PEMS-BAY，Wiki-Traffic Prediction，M5 ），并在表 4.1 中进行了总结。有关每个数据集的更多详细信息，请参阅附录 C。对于这些数据集，我们考虑了各种归一化预处理步骤 $p$： $\mathrm{Z}(x):=\frac{x-\mu}\sigma $ ，其中 $\mu$ 是平均值，$\sigma$ 是标准差，对数转换 $\text{n}\log(x):=\log(x+1)$ ，以及复合使用 $\mathrm{Z}(\log(x)):=\mathrm{Z}(\log(x+1))$。

<!-- TODO 补充表和附录 -->

特征工程也被视为对输入的预处理步骤，具体内容在附录 C 中有详细介绍，并且取决于数据集的属性。对于需要在基础数据上进行拟合的预处理函数，它们在 $\mathcal{D}_{train}$ 上完成。依据每个数据集的训练分裂情况，将验证集 $\mathcal{D}_{val}$ 和测试集 $\mathcal{D}_{test}$ 数据划分进行标准化。

### 4.2 模型详细信息

在我们的实验中，考虑的模型包含了经过良好验证的参考实现，并在上一节列出的数据集上展示了最先进的性能。这些模型在提出的框架中重新实现和优化，其性能达到或超过了参考实现。这些模型的概要在表 4.2 中给出。
每个模型都有一组相应的超参数 $\lambda_{m}$ ，这些参数涉及到隐藏维度大小、层数等，每个数据集和模型考虑的完整列表和范围都在附录 D.1 中说明。注意，这些模型中也包括一个强大的基线 XGBoost，经常在比赛中使用，配备额外的特征工程预处理步骤进行竞争。

### 4.3 评估指标

当评估每个模型时，我们考虑以下指标：

- 平均绝对误差(MAE)：$\frac1n\sum^n|X^+-\hat{X}^+|$
- 均方根误差(RMSE)：$\sqrt{\frac1n\sum^n(X^+-\hat{X}^+)^2}$
- 对称平均绝对百分比误差(SMAPE)：$\frac1n\sum^n\frac{|X^+-\hat{X}^+|}{(|X^+|+|\hat{X}^+|)/2}*100$

无论预测窗口 h 如何，每个指标都是逐点计算的。许多论文使用 MAPE[39,32,35,36]或 q-risk[23,30]度量，而 MAPE 是无界的（如果真值接近 0），我们选择使用 SMAPE 代替。

### 4.4 训练循环和优化器

不论模型和数据集如何，都有可以在训练时间序列预测模型时利用的技术，以提高性能。特别是优化器的选择，例如 Adam [20]及其超参数如初始学习率，动量等。可以直接修改训练循环的技术，如指数移动平均（EMA），其中一个离线模型使用类似于[12,18]的指数移动平均来跟踪模型权重；或者课程学习（CL）[1]也被认为是可调的。

## 5. 结果

<!-- TODO 补一个表 -->

表 4 总结了在提出的框架和实验设置中，不同模型在目标数据集上的实证性能。值得注意的是，深度学习模型在几个独立的数据集上展现出强有力的竞争性能，与利用选择性特征工程和专家知识的 XGBoost 模型相比，这个发现挑战了传统的，依赖特征工程的模型在时间序列预测任务中一贯优于深度学习方法的假设。而且，结果展示了没有一个模型在所有数据集上都能称霸，这突显了在选择预测模型时考虑特定数据特性的重要性。

在个体模型的表现基础上，我们尝试了集成学习，一个被广泛认可的提升时间序列任务预测精度的策略[9]。为此，我们训练了最多 256 个每个模型的实例，这些模型的超参数是从不同的随机种子中优化得来的，导致预测器的集成具有多样性。最终的预测通过通过预测平均进行决策融合，利用集成的集体智慧；表 5 呈现了集成模型结果的总结。通过在这些模型上进行的实验，可以得出一系列的观察：

**度量标准**：不同的模型可能根据选择的度量标准有所优势，这强调了考虑度量集合以进行模型比较的重要性。我们排除了 TDI 指标，因为调谐器无法有效地利用它用于模型辨别。这突显了需要包括多个既有信息又易于被自动优化工具使用的评估度量标准的需要。

**批大小的影响**：与推荐更小或更大批大小的领域特定建议相反，我们的发现建议批量大小与特定的数据集和模型之间的联系更紧密。例如，DeepAR 更偏好小批量大小，而 N-BEATS 对这个超参数则不敏感，TFT 需要一个特定的范围。

**CL&EMA**：与以前的声明相反，研究的训练技术并未在所有数据集中一致地提高性能。值得注意的是，课程学习（CL）提供的改进微乎其微，尽管我们希望调谐器启用它。指数移动平均（EMA）产生了混合的结果，可能是由于预测任务中的噪声以及 EMA 平滑的负面效果。

**上下文长度(l)**：最优上下文长度强依赖于特定的模型和数据集组合。这意味着一个单一的，普遍的上下文长度建议不太可能在所有模型和数据集上都有效。例如，N-BEATS 和 NHITS 在提供有限的上下文（少于 256 个数据点）时表现糟糕，但在能够接触到更丰富的上下文（大于 256 个数据点）时，它们的性能大大提高。

**弱模型在集成中作为强基线**：DeepAR, 尽管在单独训练（例如，在 WikiTraffic 数据集上）时性能欠佳，但在并入集合时表现出了显著的转变。如表 5 所示，利用 DeepAR 的集成实现了明显优于其他模型的性能。这个有趣的发现突显了看起来弱的模型在集成设置中作为强大基线的潜力。通过利用个体模型的多样化优点，集成可以集体实现优越的性能，即使一些组件在单独使用时表现欠佳。

## 6 结论

时间序列预测领域的标准化缺乏构成了阻碍进步的重大障碍。这个问题在不一致的报告实践中体现，即使使用同一个数据集，由不同研究报告的指标差异就可以证明这一点[23, 35, 37]。此外，频繁报告使用次优超参数获得的结果进一步模糊了不同模型的真正性能潜力，使得难以明确判断他们的相对优势和劣势[23]。本工作通过提出一个标准化的工作流程和框架来解决这些挑战，这个框架促进了多样化数据集和训练/推理逻辑的无缝集成。此外，此框架在整个工作流程中透明地揭示了决策流程，使得优化工具可以在他们的探索中引导研究人员和开发人员。

我们的实证评估揭示了深度学习方法对 XGBoost 模型展示出有竞争力的性能，挑战了依赖特征工程的方法在这个领域中一直占主导地位的传统观念。通过推动标准化和透明度，本工作为时间序列预测领域更健壮和可复制性研究开辟了道路。

## A 附加实验

### A.1 回顾窗口长度的影响

在这一部分，我们对回顾窗口长度 l 对最终模型性能的影响进行了附加研究。特别是，MTGNN 和 DCRNN 设计用于处理包含许多系列的大块数据，即它们在局部多变量设置（n = 1, d = 325）中运作，这对批大小或回顾窗口施加了限制。为了比较，我们也训练了 TFT，DeepAR，N-BEATS 和 N-HITS 在 PEMS-BAY 上，与 MTGNN 和 DCRNN 相同的回顾窗口，如表 4 所示的结果。时间序列预测任务的终极目标应该是基于所有可用历史预测未来值，而不考虑上下文长度。为此，除了 12 的回顾窗口长度外，我们还对其进行了 24、48 和 288 的扫描，然后对每个模型应用我们在第 3.5 节中定义的相同过程。最佳配置的结果在表 6 中提供。

值得一提的是，回顾窗口越长，模型训练的时间通常越长。这意味着，对于同样的计算预算 B，HPO 算法可能无法找到较长回顾窗口的最优配置，因此这里存在固有的权衡。在表 6 中展示的结果是 HPO 找到的最佳配置的结果。这些结果因训练这些模型的随机性而偏向于较低的错误。对最佳配置进行了稳定性测试，使用大于 100 个模型的样本，结果汇总在表 7 中。此外，XGBoost 模型的最佳配置由一个领域专家 Kaggle 大师手动制作，相比于其他模型，此配置使用了较大的回顾窗口。

### A.2 指数移动平均和课程学习的效果

在我们的搜索中，我们将 EMA 和 CL 视为可以在寻找最佳模型配置时打开或关闭的训练技术。尽管 TPE 算法持有包含关于特定超参数有多大益处的信息的内部状态，但解释这个状态是很难的。相反，我们总结了在最终模型中选择此技术的顶级配置，见表 8。总的来说，EMA 被发现对于提高下游性能非常有用。关于课程学习，我们考虑了 MTGNN，这是作者在他们提出的方法中明确使用的。因此，对 MTGNN 模型的这个超参数进行了搜索。从表 9 中总结的结果，我们发现，在电力和 PEMS-BAY 上，HPO 算法倾向于选择有较低课程学习更新步骤的配置，这反映出 HPO 过程有关闭这个特性的倾向。

### A.3 性能分析

在表 10 中，我们提供了训练每个顶级性能模型所需的平均时间。时间是根据收敛到最佳检查点所需的平均迭代次数来计算的。我们观察到 TFT 一贯需要的训练时间少于 XGBoost，同时达到了可比较的错误。

## B 框架流程图

模型对超参数变化的高度敏感性和精度的高变动性要求我们必须在实验中严谨。为了确保公正的比较，实验流程的某些部分必须是固定的（训练/验证/测试划分，指标，超参数优化算法）。然而，其他部分必须由超参数优化算法使用超参数空间 S 来进行采样：模型结构参数，训练循环，预处理和后处理算法。

## C 数据集

下面，我们对每个数据集提供更详细的描述，并说明它们如何被处理/标准化以用于实验。

1. 电力
   电力负荷图[33]（不要与电力[15]混淆）是一个常用的[23,30,37]数据集。它由 369 个不同的单变量时间序列组成，没有额外的协变量。对于我们的实验，数据的处理方式如[23]和[30]中所述，我们在 2014-01-01 至 2014-09-01 之间随机选择了 500k 个样本作为训练集，其中最后一周用作验证划分。测试集是在验证集之后的一周，从 2014-09-01 00:00:00 到 2014-09-07 23:00:00。我们在每个系列上单独计算训练集(排除验证子划分)的 z 得分，并分别应用到每个系列。
1. PEMS-BAY
   加州交通性能测量系统[PeMS](28)是一个覆盖加州所有主要都市区的高速公路系统的交通测量系统。该系统由 15000 多个传感器组成。在文献中可以找到在这些数据的不同子集上评估模型的模型。最常用的是根据[22]所描述的 PEMS-BAY。对于需要图定义的我们的实验，我们使用由 DCRNN 作者预先计算的图，以尽可能接近其他论文[39, 32, 3, 35]。每个数据点是一个统计量的 5 分钟总和，由一个单独的传感器收集的交通数据。目标是使用前一小时作为先验来预测下一小时（12 个时间步）的交通情况。该数据集包括相同的 325 个选择的时间序列，其中训练划分范围从 2017-01-01 到 2017-05-08，验证划分从 2017-05-08 到 2017-05-25 17:50:00，测试划分从 2017-05-25 17:50:00 到 2017-07-01。测试划分的前 12 步用作模型的编码器输入，因此标签范围从 2017-05-25 18:50:00 到 2017-07-01。
1. M5
   Kaggle M5[26]竞赛的目标是精确预测 Walmart 各店铺的单位销售的 30.5k 的值的接下来的 28 天。用于这次比赛的数据集有一个层次结构，其中每一层都由按照特定标准进行汇总的条目组成，例如使用相同的位置、产品或产品类别等。总共有 42,840 个系列分布在 12 个汇总层次。对所有系列（包括汇总系列）进行了评估，采用 RMSE 指标。在我们的实验中，使用的数据集与 M5 比赛中的完全一样。我们采用标准的训练/验证/测试切分：2011-01-29 至 2016-04-24 的数据用于训练集，2016-04-25 至 2016-05-22 的数据用于验证集，2016-05-23 至 2016-06-19 的数据用于测试集。在我们的实验中，使用了一个长度为 28 的编码器，导致示例总长度为 56。由于我们问题设定的特性，我们希望用一个模型来预测所有的时间序列，我们采用自下而上的方法，只尝试预测第 12 级（汇总级别最低）的序列，然后汇总预测以产生更高级别的预测，无需做任何纠正。
1. Wiki 流量
   Kaggle 网络流量时间序列预测[11]竞赛的目标是预测 145k 个网页在 10 个 Wikimedia 站点上收集的下两个月的每日"点击"（访问）。作者选择使用 SMAPE 作为目标指标来评价模型的性能。该数据集由不同程度流行性的时间序列组成，这增加了复杂性，因为模型必须对尺度变化有强烈的抗性，但更重要的是，由于这个挑战的数据是在收到后才收集的，而原始训练集中的所有页面都没有在比赛结束时存在，这些页面从测试评估中排除。此外，原始数据在验证集和测试集之间有 2 天的间隔，因为最后的训练和验证集是在开始收集测试数据的 2 天前发布的。这就是为什么我们使用修改过的训练/验证/测试范围来弥补这个间隔：对于训练集，我们使用了 2015-07-01 至 2017-07-08 的数据，对于验证集，我们使用了 2017-05-06 至 2017-09-10 的数据，对于测试集，我们使用了 2017-07-09 至 2017-11-13 的数据。这样，在排除了 64 个编码器输入后，我们生成了 2017-09-11 至 2017-11-13 的测试集，而不是原始比赛数据中的 2017-09-13 至 2017-11-13。我们使用比 62 更长的 64 预测时间跨度以使数据集连续，但我们为测试集的前 2 个值分配零权重，以产生与比赛期间使用的指标可比的指标。我们从每个序列的开始删除零值。在移除零前缀后，训练集中包含少于 64 个观察值的系列会完全从数据集中排除。

## D 调谐器

在本节中，我们将提供关于每个超参数所考虑的具体范围的更多细节（即在进行实验和评估时指定 A 和调谐器设置）。

### D.1 模型超参数

表 D.1 中提供了各种模型使用的超参数的总结，其中括号"()"表示范围，逗号分隔的值是明确的选项，括号围住的是模型特定的配置。


<table>
    <thead>
        <tr>
            <th>Model</th>
            <th>Parametername</th>
            <th>Parameterrange</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan="3">TFT</td>
            <td>#head</td>
            <td>1,2, 4</td>
        </tr>
        <tr>
            <td>hidden size</td>
            <td>96,128, 192, 256</td>
        </tr>
        <tr>
            <td>dropout</td>
            <td>(0,0.5)</td>
        </tr>
        <tr>
            <td rowspan="17">N-BEATS</td>
            <td>stack0 type</td>
            <td>trend,generic</td>
        </tr>
        <tr>
            <td>stack1 type</td>
            <td>seasonality,generic</td>
        </tr>
        <tr>
            <td>stack0 # blocks</td>
            <td>2, 4,8</td>
        </tr>
        <tr>
            <td>stack1 # blocks</td>
            <td>2, 4,8</td>
        </tr>
        <tr>
            <td>stack0 theta dim</td>
            <td>2, 4,8, 16</td>
        </tr>
        <tr>
            <td>stack1 theta dim</td>
            <td>0, 2,4, 8, 16</td>
        </tr>
        <tr>
            <td>stack0 share weights</td>
            <td>True,False</td>
        </tr>
        <tr>
            <td>stack1 share weights</td>
            <td>True,False</td>
        </tr>
        <tr>
            <td>stack0 hidden size</td>
            <td>256,512, 1024, 2048, 4096*</td>
        </tr>
        <tr>
            <td>stack1 hidden size</td>
            <td>256,512, 1024, 2048, 4096*</td>
        </tr>
        <tr>
            <td>mlp layers</td>
            <td>2,3,4</td>
        </tr>
        <tr>
            <td>hidden size</td>
            <td>256,512,1024,2048</td>
        </tr>
        <tr>
            <td>activation</td>
            <td>ReLU,Softplus, Tanh, SELU, LeakyReLU, PReLU, Sigmoid</td>
        </tr>
        <tr>
            <td>pooling mode</td>
            <td>MaxPool1d,AvgPool1d</td>
        </tr>
        <tr>
            <td>#blocks</td>
            <td>[1,1,1],[1,1,2],[1,2,1],[1,2,2],[2,1,1],[2,1,2],[2,2,1],[2,2,2]</td>
        </tr>
        <tr>
            <td>poolkernel size</td>
            <td>[6,3,1],[6,2,1],[4,2,1],[3,3,1],[2,2,1]</td>
        </tr>
        <tr>
            <td>freq downsample</td>
            <td>[6,3,1],[6,2,1],[4,2,1],[3,3,1],[2,2,1]</td>
        </tr>
        <tr>
            <td rowspan="3">DeepAR</td>
            <td>#layers</td>
            <td>2,3,4,5</td>
        </tr>
        <tr>
            <td>hidden size</td>
            <td>64,128,256, 512, 1024, 2048**</td>
        </tr>
        <tr>
            <td>dropout</td>
            <td>(0,0.6)</td>
        </tr>
        <tr>
            <td rowspan="13">MTGNN</td>
            <td>gcn depth</td>
            <td>2,3,4</td>
        </tr>
        <tr>
            <td>dropout</td>
            <td>(0,0.5)</td>
        </tr>
        <tr>
            <td>subgraph size</td>
            <td>10,15,20</td>
        </tr>
        <tr>
            <td>node dim</td>
            <td>32,40,64,128</td>
        </tr>
        <tr>
            <td>conv channels</td>
            <td>16,32,64</td>
        </tr>
        <tr>
            <td>residual channels</td>
            <td>16,32,64</td>
        </tr>
        <tr>
            <td>skip channels</td>
            <td>32,64</td>
        </tr>
        <tr>
            <td>end channels</td>
            <td>32,64</td>
        </tr>
        <tr>
            <td>#layers</td>
            <td>2,3,4</td>
        </tr>
        <tr>
            <td>propalpha</td>
            <td>(0.01,0.2)</td>
        </tr>
        <tr>
            <td>tanalpha</td>
            <td>(2.0,4.0)</td>
        </tr>
        <tr>
            <td>in dim</td>
            <td>16,24, 32, 64</td>
        </tr>
        <tr>
            <td>embedding</td>
            <td>True,False</td>
        </tr>
        <tr>
            <td rowspan="4">DCRNN</td>
            <td>maxdiffusion step</td>
            <td>1,2</td>
        </tr>
        <tr>
            <td>#RNN layers</td>
            <td>2,3</td>
        </tr>
        <tr>
            <td>RNN units</td>
            <td>32,64, 128</td>
        </tr>
        <tr>
            <td>activation</td>
            <td>tanh,ReLU</td>
        </tr>
    </tbody>
</table>
